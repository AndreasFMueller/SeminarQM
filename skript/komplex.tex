\chapter{Anhang: Komplexe Zahlen}
\lhead{Komplexe Zahlen}
\rhead{}
Der mathematische Formalismus der Quantenmechanik kann nicht ohne komplexe
Zahlen auskommen.
Leonhard Euler sah die Zahlen $\sqrt{-1}$ noch als imagin"ar an,
also als ohne Gegenst"uck in der realen Welt.
Elektroingenieure verwenden komplexe Zahlen mit grossem Erfolg in ihren
Anwendungen, sie spielen aber vor allem die Rolle eines praktischen
Werkzeugs. Die Regeln, mit denen am Schluss solcher Rechnungen sichergestellt
wird, dass die Resultate reell sind zeigt ausserdem, dass man alles auch
ohne komplexe Zahlen durchrechnen k"onnte, wenn auch wesentlich weniger
elegant.

In der Quantenmechanik geht es aber nicht mehr ohne komplexe Zahlen,
die physikalischen Gr"ossen selbst sind komplex. Es gibt zwar auch
hier wieder Regeln, die sicherstellen, dass Messresultate reell sind
(Operatoren m"ussen selbstadjungiert sein), aber sie erlauben nicht,
die ganze Quantenmechanik auf eine Art zu beschreiben, die ohne komplexe
Zahlen auskommt.

\section{Der K"orper $\mathbb C$ der komplexen Zahlen}
In den reellen Zahlen $\mathbb R$ k"onnen alle Grundoperationen ausgef"uhrt
werden, es ist jedoch nicht m"oglich, die Quadratwurzeln aus negativen
Zahlen zu ziehen. Eine analoge Situation trifft man schon viel fr"uher.
In den nat"urlichen Zahlen $\mathbb N$ kann man zwar addieren und
multiplizieren, aber nicht subtrahieren.
F"ugt man die negativen Zahlen hinzu erh"alt man eine Menge $\mathbb Z$,
in der die Subtraktion uneingeschr"ankt m"oglich ist. Division ist aber
immer noch nur f"ur spezielle Divisoren m"oglich. F"ugt man jedoch die
Br"uche zu $\mathbb Z$ hinzu, erh"alt man die Menge der rationalen Zahlen
$\mathbb Q$, in der Division uneingeschr"ankt m"oglich ist.
Doch auch $\mathbb Q$ ist nicht vollst"andig, die Zahl $\sqrt{2}$ ist
keine rationale Zahl. Nat"urlich kann man $\sqrt{2}$ durch eine
Folge von Br"uchen $r_n\in\mathbb Q$ approximieren, doch der Grenzwert
dieser Folge $\lim_{n\to\infty}r_n=\sqrt{2}$ ist nicht in $\mathbb Q$.
F"ugt man jedoch alle Grenzwerte von konvergenten Folgen zu $\mathbb Q$
hinzu, erh"alt man die Menge $\mathbb R$ der reellen Zahlen, in der
auch beliebige Wurzeln von positiven Zahlen gezogen werden k"onnen,
oder andere Grenzwerte wie $\pi$, $e$, die Werte von $\sin x$ und $\cos x$
und weitere.

\subsection{Grundoperationen f"ur die komplexen Zahlen}
Nach analogem Muster k"onnen wir auch $\mathbb R$ erweitern, so dass auch
die Wurzeln aus negativen Zahlen bestimmt werden k"onnen. Es reicht
sogar, nur die Wurzel von $-1$ hinzuzuf"ugen, denn jede andere Wurzel
einer negativen Zahl ist $\sqrt{-a}=\sqrt{-1}\cdot\sqrt{\mathstrut a}$.
Euler hat die Bezeichnung $i=\sqrt{-1}$ f"ur die imagin"are Einheit eingef"uhrt.
Es gilt nat"urlich $i^2=-1$.

\begin{definition}
Die Menge $\mathbb C=\{a+bi\,|\,a,b\in\mathbb R\}$ heisst die Menge der
komplexen Zahlen. Die komplexe Zahl $z=a+bi$ hat
Realteil $\operatorname{Re}z=a$ und Imagin"arteil $\operatorname{Im}z=b$.
Die Rechenoperationen sind so zu verstehen, die Rechenregeln
der Algebra erhalten bleiben\footnote{Man nennt dies das Permanenz-Prinzip}.
\end{definition}

Die Rechenoperationen folgen aus der Definition:
\begin{align*}
(a+bi)+(c+di)&=(a+c)+(b+d)i\\
(a+bi)(c+di)&=ac-i^2bd+(ad+bc)i=ac-bd+(ad+bc)i
\end{align*}
Die Division stellt noch ein Problem dar. Hier hilft das Konzept der
konjugiert komplexen Zahl.

\begin{definition}
Die Zahl $\bar z=a-bi$ heisst die zu $z=a+bi$ konjugiert komplexe Zahl.
\end{definition}

Zun"achst kann man mit der konjugiert komplexen Zahl den Betrag einer
komplexen Zahl definieren:
\[
z\bar z=(a+bi)(a-bi)=a^2+abi-abi-i^2b^2=a^2+b^2\qquad\Rightarrow\qquad
|z|^2=z\bar z.
\]
Andererseits kann man damit auch komplexe Br"uche berechnen, indem man
mit der konjugiert komplexen Zahl des Nenners erweitert:
\begin{align*}
\frac{a+bi}{c+di}&=
\frac{a+bi}{c+di}
\cdot
\frac{c-di}{c-di}=\frac{ac-bd+(ad+bd)i}{c^2+d^2}
\end{align*}
Die komplexen Zahlen k"onnen in einer Ebene visualisert werden: 
Realteil und Imagin"arteil werden entlang orthogonaler Achsen abgetragen.
Die Punkte $(x,y)$ der $x$-$y$-Ebene entsprechen also der komplexen Zahl
$x+yi$ der komplexen Zahlenebene.

Mit Hilfe der komplexen Konjugation kann man den Real- and Imagin"arteil
einer komplexen Zahl $z=a+bi$ direkt ausdr"ucken:
\begin{align}
\operatorname{Re}z 
&=
a=\frac{(a+bi)+(a-bi)}2=\frac{z+\bar z}2
\label{realteil-formel}
\\
\operatorname{Im}z
&=
b=\frac{(a+bi)-(a-bi)}{2i}=\frac{z-\bar z}{2i}.
\label{imaginaerteil-formel}
\end{align}

\subsection{Polardarstellung}
Die Darstellung der komplexen Zahlen als Punkte einer Ebene suggeriert
auch eine alternative Schreibweise.
Ein Punkt $z$ der komplexen Ebene kann auch charakterisiert werden mit Hilfe von
Polarkoordinaten, also durch seine Entfernung $r=|z|$ vom Nullpunkt,
und durch Polarwinkel zwischen der reellen Achse und der Richtung
zur komplexen Zahl. Der Polarwinkel heisst auch Argument $\operatorname{arg}z$,
und es gilt
\[
\tan\operatorname{arg}z=\frac{\operatorname{Re}z}{\operatorname{Im}z}.
\]
Die Multiplikation von komplexen Zahlen bekommt in der Polardarstellung
eine besondere Interpretation:
\begin{align*}
z_1z_2
&=
(r_1\cos\varphi_1+ir_1\sin\varphi_1) (r_2\cos\varphi_2+ir_2\sin\varphi_2)
\\
&=
r_1r_2(\cos\varphi_1+i\sin\varphi_1) (\cos\varphi_2+i\sin\varphi_2)
\\
&=
r_1r_2\bigl(
\cos\varphi_1\cos\varphi_2-\sin\varphi_1\sin\varphi_2 +
(\cos\varphi_1\sin\varphi_2+\sin\varphi_1\cos\varphi_2)i\bigr)
\\
&=
r_1r_2(\cos(\varphi_1+\varphi_2)+i\sin(\varphi_1+\varphi_2))
\\
\Rightarrow \operatorname{arg}z_1z_2&=\arg z_1 + \arg z_2
\end{align*}
Die Multiplikation zweier komplexen Zahlen entspricht also der
Multiplikation der Betr"age, und der Addition der Argumente.

Wir versuchen jetzt, die Werte der Exponentialfunktion zu $e^z$ zu
bestimmen.
Die Exponentialgesetze sollten auch weiterhin gelten.
Sei also $z=a+bi$, dann ist
\[
e^z=e^{a+bi}=e^a\cdot e^{bi}.
\]
Die Exponentialfunktion reeller Zahlen ist bereits wohlbekannt, es muss
also nur noch untersucht werden, welche Bedeutung $e^{bi}$ hat.

Betrachten wir die Funktion $f(t)= e^{ti}$. Die Ableitungen von $f$ sind
\begin{align}
f'(t)&=ie^{ti}=if(t)\notag\\
f''(t)&=-f(t).\label{exp-dgl}
\end{align}
Die Funktion $f$ muss also eine L"osung der Differentialgleichung
(\ref{exp-dgl}) sein, welche die Anfangsbedingungen $f(0)=1$ und
$f'(0)=if(0)=i$ erf"ullen muss.
Doch die Differentialgleichung (\ref{exp-dgl}) hat die L"osungen
\[
f(t)=a\cos t+b\sin t.
\]
Setzt man die Anfangsbedingungen ein findet man
\begin{align*}
f(0)&=1&\Rightarrow&&a&=1\\
f'(0)&=1&\Rightarrow&&b&=i,
\end{align*}
so dass wir jetzt $e^{ti}$ ausrechnen k"onnen:
\begin{satz}[Euler]
\begin{align}
e^{it}=\cos t+i\sin t.
\label{euler-formula}
\end{align}
\end{satz}

Die komplexe Konjugation kehrt das Vorzeichen des Imagin"arteils, also 
von $\sin t$. Da $\sin t$ eine ungerade Funktion ist, ist dies gleichbedeuten
damit, das Vorzeichen von $t$ zu kehren: $\overline{e^{it}}=e^{-it}$.

Mit der Eulerschen Formel sind wir jetzt auch in der Lage, den Zusammenhang
zwischen einer komplexen Zahl und ihrem Betrag und Argument sehr pr"agnant
auszudr"ucken:
\[
z=|r|\cdot e^{i\operatorname{arg}z}.
\]
Die Real- und Imagin"arteile von $e^{it}$ sind $\cos t$ und $\sin t$,
wir k"onnen Sie auch mit den Formeln (\ref{realteil-formel}) und
(\ref{imaginaerteil-formel}) ausdr"ucken:
\begin{align*}
\cos t
&=
\operatorname{Re}e^{it}
=
\frac{e^{it}+\overline{e^{it}}}2
=
\frac{e^{it}+e^{-it}}2
\\
\sin t
&=
\operatorname{Im}e^{it}=\frac{e^{it}-e^{-it}}{2i}.
\end{align*}

\subsection{Matrixdarstellung der komplexen Zahlen}
Die Algebra der komplexen Zahlen kann man auch als eine Algebra von Matrizen
schreiben. Dazu betrachten wir die Abbildung
\[
\varphi\colon
\mathbb C\to M_2(\mathbb R):
a+bi\mapsto\begin{pmatrix}a&b\\-b&a\end{pmatrix}
\]
Die imagin"are Einheit $i$ wird von $\varphi$ auf die Matrix
\[
\varphi(i)=J=\begin{pmatrix}0&1\\-1&0\end{pmatrix}
\]
abgebildet. Man kann nachrechnen, dass $J^2=-E$, und dass die Rechenregeln
f"ur die komplexen Zahlen durch die Abbildung $\varphi$ in die Rechenregeln
f"ur Matrizen transformiert werden.
Wir illustrieren dies f"ur die Multiplikation:
\begin{align*}
&(a+bi)(c+di)&&\mapsto&
&\begin{pmatrix}a&b\\-b&a\end{pmatrix}
\begin{pmatrix}c&d\\-d&c\end{pmatrix}
\\
&(ac-bd) + i(ad-bc)&&\mapsto&
&=\begin{pmatrix}
ac-bd&ad-bc\\
-ad+bc&ac-bd
\end{pmatrix}
\end{align*}

\section{Komplexe Matrizen}
Die Lineare Algebra im Bachelor wird typischerweise nur in den
reellen Zahlen entwickelt, der einzige untersuchte Vektorraum ist
der Raum $\mathbb R^n$ der reellen $n$-dimensionalen Vektoren.
F"ur die Quantenmechanik ben"otigen wir aber auch Vektoren mit
komplexen Komponenten. Der $n$-dimensionale komplese Vektorraum
$\mathbb C^n$ ist die Menge
\[
\left\{\left.\begin{pmatrix}c_1\\\vdots\\c_n\end{pmatrix}\,\right|
c_i\in\mathbb C\right\},
\]
mit der komponentenweisen Addition und der Multiplikation mit einer
komplexen Zahl. Nichts an der elementaren linearen Algebra hat besondere
Eigenschaften der reellen Zahlen verwendet, die nicht auch die komplexen
Zahlen haben. Der Gauss-Algorithmus, die Konstruktion der Determinanten,
ja sogar der grundlegende Algorithmus zur L"osung des Eigenwertprobems
funktioniert genau gleich auch f"ur komplexe Matrizen. Nur im Bereich
des Skalarproduktes sind minimale Modifikationen notwendig, damit

\subsection{Skalarprodukt f"ur komplexe Vektorr"aume}
In der linearen Algebra im ersten Semester wird das Skalarprodukt
geometrisch mit Hilfe der Projektion eingef"uhrt.
Eine solche Konstruktion ist f"ur komplexe Vektoren nicht m"oglich,
weil es keine anschauliche komplexe Geometrie gibt.

\subsubsection{Komplexes Skalarprodukt}
Um ein komplexes Skalarprodukt zu bekommen, gehen wir daher von den
algebraischen Eingeschaften des Skalarproduktes aus:
\begin{compactenum}
\item Das Skalarprodukt $(u,v)$ von komplexen Vektoren $u$ und $v$ ist linear
in $v$.
\item $(u,u) > 0$ falls $u\ne 0$.
\item Falls $(u,v)\in\mathbb R$, dann ist $(u,v)=(v,u)$.
\end{compactenum}
Diese Eigenschaften m"ussen auch f"ur ein komplexes Skalarprodukt gelten.
Wir zeigen, dass diese Eigenschaften auch ein komplexes Skalarprodukt 
weitgehend festlegt.

Zun"achst stellen wir fest, dass wir nicht erwarten k"onnen, dass
ein Skalarprodukt linear sein kann.
Betrachten wir dazu einen eindimensionalen Vektorraum $\mathbb C^1$.
Vektoren sind hier nur komplexe Zahlen, und ein Produkt, welches
linear in beiden Faktoren ist, ist von der Form $(u,v)=uv$. Dann ist
aber $(u,u)=u^2$, aber $u^2$ kann auch negativ sein, zum Beispiel f"ur $u=i$.
Das einzige Produkt, welches immer positiv ist, ist $(u,v)=\bar uv$.
Dieses Produkt ist aber nicht linear im Faktor $u$:
\[
(\lambda u,v)=\overline{(\lambda u)}v=\bar\lambda (\bar uv)=\bar\lambda (u,v).
\]
Wir m"ussen also von einem komplexen Skalarprodukt verlangen, dass es
im ersten Faktor {\em konjugiert linear} ist:
\[
(\lambda u,v)=\bar\lambda(u,v)
\]
Eine Funktion von zwei Vektoren, welche linear im zweiten Vektor ist
und konjugiert linear im ersten heisst {\em sesquilinear}.

Sei jetzt also $(\,\cdot\,|\,\cdot\,)$ eine Sesquilinearform.
Wir setzen $\lambda = 1/(u,v)$, dann gilt
$(u,\lambda v)$ reell ist. Dann gilt
\begin{align*}
1&=\lambda (u,v)=(u,\lambda v)=(\lambda v,u)=\bar\lambda(v,u)
&
&\Rightarrow&
\frac1{(\bar\lambda)}&=(v,u)
&
&\Rightarrow&
\overline{(u,v)}&=(v,u).
\end{align*}
Vertauschung der Faktoren ist also gleichbedeutend mit komplexer Konjugation
des Wertes des Skalarproduktes. Man nennt eine Funktion von zwei komplexen
Vektoren {\em hermitesch}, wenn $(u,v)=\overline{(v,u)}$ gilt.

Eine hermitesche Sesquilinearform heisst {\em positiv definit}, wenn
f"ur jeden Vektor $u\ne 0$ gilt $(u,u)>0$. Diese Eigenschaft stellt
sicher, dass $(u,u)$ sinnvoll als die ``L"ange'' eines Vektors interpretiert
werden kann.

\begin{definition}
Ein komplexes Skalarprodukt ist eine positiv definite,
hermitesche Sesquilinearform.
\end{definition}

Das einfachste Beispiel eines komplexen Skalarproduktes ist
\[
(u,v)=\sum_i \bar u_iv_i.
\]
Die Standardbasisvektoren sind auch in diesem Skalarprodukt
orthonormiert.

\subsubsection{Adjungierte Matrix}
In den reellen Vektorr"aumen konnte man zu einer linearen $A$ immer
eine lineare Abbildung $A^t$ finden mit der Eigenschaft
$(u,Av)=(A^tu,v)$. Mit Hilfe der Standardbasisvektoren konnte
man auch ausrechnen, was dies f"ur die Matrizen von $A$ bedeutet:
\[
(e_i,A^te_j),
=
(A^te_j, e_i)
=
(e_j,Ae_i)=a_{ij}
\]
d.~h.~die Matrix von $A^t$ ist die transponierte Matrix von $A$.
Eine symmetrische Matrix war eine, die sich beim Transponieren nicht
"andert, also $A^t=A$.

Dasselbe kann man jetzt auch f"ur ein komplexes Skalarprodukt
versuchen. Zu einer komplexen Matrix $A$ ist also eine neue
Matrix $A^*$ gesucht, mit der Eigenschaft, $(A^*u,v)=(u,Av)$ f"ur 
jedes Paar von Vektoren $u$ und $v$. F"ur die Standardbasisvektoren
gilt dann
\[
(e_i,A^*e_j),
=
\overline{(A^*e_j, e_i)}
=
\overline{(e_j,Ae_i)=a_{ij}},
\]
die Matrix von $A^*$ ist also nicht nur transponiert, sondern auch komplex
konjugiert. Hat $A$ die Matrixelement $a_{ij}$ dann nennt man
die Matrix $A^*$ mit den Matrixelementen $\bar a_{ji}$ die
adjungiert Matrix. Eine Matrix, die sich beim adjungieren nicht
"andert heisst selbstadjungiert.

\subsubsection{Unit"are Matrizen}
Matrizen, die in reellen Vektorr"aumen das Skalarprodukt nicht "andern,
heissen orthogonal. Sie sind charakterisiert durch die Eigenschaft
$(Ox,Oy)=(x,y)$, woraus sich mit Hilfe der Transposition ergibt:
\[
(Ox,Oy)=(O^tOx,y)=(x,y)\qquad\Rightarrow\qquad O^tO=E,
\]
woraus man weiter ablesen kann, dass bei orthogonalen Matrizen
die transponierte Matrix mit der invertierten Matrix zusammenf"allt.

F"ur komplexen Vekoren kann man wieder nach den Matrizen fragen, die das
komplexe Skalarprodukt nicht ver"andern. Eine Matrix $U$ hat diese
Eigenschaft, wenn
\[
(Ux,Uv)=(U^*Ux,y)=(x,y)\;\forall x,y
\qquad\Rightarrow\qquad
U^*U=E,
\]
eine solche Matrix heisst unit"ar. 

F"ur reelle Matrizen $A$ ist $A^t=A^*$, also sind orthogonale Matrizen
auch unit"ar.

\begin{beispiel}
Die unit"aren $1\times 1$-Matrizen sind komplexe Zahlen $z$, welche
die zus"atzliche Bedingung $\bar zz=1$ erf"ullen m"ussen.
Die Menge der unit"aren $1\times 1$-Matrizen ist also
\[
U(1)=\left\{ z\in\mathbb C\,|\, |z|=1
\right\}.
\]
In der Quantenmechanik k"onnen Zustandsvektoren in der Regel nur bis auf
einen komplesen Faktor vom Betrag $1$, also bis auf ein Element
von $U(1)$ festgelegt werden.
Man spricht oft von ``bedeutungslosen'' Phasenfaktoren.
\end{beispiel}

\begin{beispiel}
Wir betrachten Matrizen der Form
\[
U=
\begin{pmatrix}
a&b\\-\bar b&\bar a
\end{pmatrix}
\]
mit der zus"atzlichen Bedingung $|a|^2 + |b|^2=1$. Sie erf"ullen
\begin{align*}
U^*U
&=
\begin{pmatrix}
\bar a&-b\\\bar b&a
\end{pmatrix}
\begin{pmatrix}
a&b\\-\bar b&\bar a
\end{pmatrix}
=
\begin{pmatrix}
\bar aa+b\bar b & \bar ab-b\bar a\\
\bar ba-a\bar b & \bar bb+a\bar a
\end{pmatrix}
=
E
\\
\det(U)&=\left|
\begin{matrix}
a&b\\-\bar b&\bar a
\end{matrix}
\right|
=
a\bar a+\bar bb = |a|^2 + |b|^2=1.
\end{align*}
Solche Matrizen sind also nicht nur unit"ar, sondern haben auch Determinante 1,
man nennt diese Matrizen die speziellen unit"aren Matrizen:
\[
\textsl{SU}(2)=\left\{
\left.
\begin{pmatrix}
a&b\\-\bar b&\bar a
\end{pmatrix}
\,
\right|
\,
a,b\in\mathbb C\wedge
|a|^2+|b|^2=1
\right\}.
\]
Die Gruppe $\textsl{SU}(2)$ spielt bei der Analyse des Elektronenspins eine 
wichtige Rolle.
\end{beispiel}

\subsection{Eigenwertproblem f"ur komplexe Matrizen}
Ein Vektor $v\ne 0$ heisst Eigenvektor zum Eigenwert $\lambda$ einer
Matrix $A$, wenn $Av=\lambda v$ gilt. Diese Definition ist auch f"ur
komplexe Matrizen g"ultig, ebenso funktioniert der Standardalgorithmus
f"ur die L"osung des Eigenwertproblems nach wie vor:
\begin{enumerate}
\item Finde die Nullstellen der charakteristischen Gleichung
$\det(A-\lambda E)=0$.
\item F"ur jede Nullstelle $\lambda_i$, finde Eigenvektoren
durch L"osung des Gleichungssystems $(A-\lambda_i E)v=0$.
\end{enumerate}
Der wesentliche Unterschied ist jedoch, dass in den komplexen
Zahlen ein Polynom vom Grade $n$ immer $n$ Nullstellen hat.
Die bei reellen Matrizen vorkommende Situation, dass weniger
als $n$ reelle Nullstellen existieren, und daher nicht gen"ugend
Eigenvektoren f"ur eine Eigenvektorbasis gefunden werden k"onnen,
tritt also bei komplexen Matrizen seltener auf.

Der quantenmechanische Formalismus beschreibt physikalische Gr"ossen
als selbstadjungierte Matrizen. Die m"oglichen Werte einer solchen Gr"osse
sind die Eigenwerte der Matrix, und es muss sichergestellt werden,
dass keine komplexen Eigenwerte auftreten k"onnen.

\begin{satz}
\label{ewreell}
Die Eigenwerte einer selbstadjungierten Matrix sind reell.
\end{satz}
\begin{proof}[Beweis]
Sei $v$ ein Eigenvektor zum Eigenwert $\lambda$ einer selbstadjungierten
Matrix $A$. Dann gilt
\begin{align*}
(v,Av)
&=
\lambda(v,v)
\\
&=(Av,v)=(\lambda v,v)=\bar\lambda(v,v)
\\
\Rightarrow \lambda&=\bar\lambda,
\end{align*}
also ist $\lambda\in\mathbb R$.
\end{proof}

Bei reellen Matrizen hat sich gezeigt, dass symmetrische Matrizen immer
diagonalisierbar sind. Dies gilt auch f"ur selbstadjungierte Matrizen
in komplexen Vektorr"aumen:

\begin{satz}
Eine selbstadjungierte Matrix ist diagonalisierbar und die Eigenvektoren zu
verschiedenen Eigenwerten sind orthogonal.
\end{satz}

\begin{proof}[Beweis]
Wir beweisen nur die Orthogonalit"at von Eigenvektoren zu verschiedenen 
Eigenwerten. Seien also $v_1,v_2$ Eigenvektoren zu zwei verschiedenen
Eigenwerten $\lambda_1,\lambda_2$. Die beiden Eigenwerte sind nach
\label{ewreell} reell. Dann gilt
\begin{align*}
(v_1,Av_2)&=\lambda_2(v_1,v_2)
\\
          &=(Av_1,v_2)=\bar\lambda_1(v_1,v_2)=\lambda_1(v_1,v_2)
\\
\Rightarrow\quad
(\lambda_1-\lambda_2)(v_2,v_2)&=0
\end{align*}
Die letzte Gleichung kann wegen $\lambda_1\ne\lambda_2$ nur wahr sein,
wenn $(v_1,v_2)=0$, die Vektoren $v_1$ und $v_2$ m"ussen also orthogonal sein.
\end{proof}


